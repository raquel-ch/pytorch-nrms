{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "In this notebook, we illustrate how to use the Neural News Recommendation with Multi-Head Self-Attention ([NRMS](https://aclanthology.org/D19-1671/)). The implementation is taken from the [recommenders](https://github.com/recommenders-team/recommenders) repository. We have simply stripped the model to keep it cleaner.\n",
    "\n",
    "We use a small dataset, which is downloaded from [recsys.eb.dk](https://recsys.eb.dk/). All the datasets are stored in the folder path ```~/ebnerd_data/*```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "epoch = 0\n",
    "num_epochs = 10\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from _constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    ")\n",
    "\n",
    "from _behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from _articles import convert_text2encoding_with_transformers\n",
    "from _polars import concat_str_columns, slice_join_dataframes\n",
    "from _articles import create_article_id_to_value_mapping\n",
    "from _nlp import get_transformers_word_embeddings\n",
    "from _python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from dataloader import NRMSDataLoader\n",
    "from model_config import hparams_nrms\n",
    "from NRMSModel import NRMSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"~/ebnerd_data\").expanduser()\n",
    "DATASPLIT = \"ebnerd_demo\"\n",
    "DUMP_DIR = PATH.joinpath(\"downloads1\")\n",
    "DUMP_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we sample the dataset, just to keep it smaller. Also, one can simply add the testset similary to the validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>85849</td><td>[9767474, 9769450, … 9762288]</td><td>[9772443, 9768308, … 9772367]</td><td>[9772443]</td><td>137547113</td><td>[1, 0, … 0]</td></tr><tr><td>676955</td><td>[9763356, 9763250, … 9764994]</td><td>[9773210, 9773248, … 9773137]</td><td>[9773248]</td><td>318808074</td><td>[0, 1, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 85849   ┆ [9767474,         ┆ [9772443,         ┆ [9772443]        ┆ 137547113     ┆ [1, 0, … 0] │\n",
       "│         ┆ 9769450, …        ┆ 9768308, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9762288]          ┆ 9772367]          ┆                  ┆               ┆             │\n",
       "│ 676955  ┆ [9763356,         ┆ [9773210,         ┆ [9773248]        ┆ 318808074     ┆ [0, 1, … 0] │\n",
       "│         ┆ 9763250, …        ┆ 9773248, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9764994]          ┆ 9773137]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "HISTORY_SIZE = 10\n",
    "FRACTION = 0.01\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(DATASPLIT, \"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3037230</td><td>&quot;Ishockey-spill…</td><td>&quot;ISHOCKEY: Isho…</td><td>2023-06-29 06:20:57</td><td>false</td><td>&quot;Ambitionerne o…</td><td>2003-08-28 08:55:00</td><td>null</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Mindre ulykke&quot;]</td><td>142</td><td>[327, 334]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr><tr><td>3044020</td><td>&quot;Prins Harry tv…</td><td>&quot;Hoffet tvang P…</td><td>2023-06-29 06:21:16</td><td>false</td><td>&quot;Den britiske t…</td><td>2005-06-29 08:47:00</td><td>[3097307, 3097197, 3104927]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;Harry&quot;, &quot;James Hewitt&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Personfarlig kriminalitet&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7084</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3037230   ┆ Ishockey- ┆ ISHOCKEY: ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ spiller:  ┆ Ishockey- ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Jeg       ┆ spilleren ┆ 06:20:57  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ troede    ┆ Seb…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ jeg…      ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3044020   ┆ Prins     ┆ Hoffet    ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7084    ┆ Negative │\n",
       "│           ┆ Harry     ┆ tvang     ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tvunget   ┆ Prins     ┆ 06:21:16  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ til       ┆ Harry til ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ dna-test  ┆ at …      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"ebnerd_demo/articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=4,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cuda:0\n",
      "torch.Size([250002, 768])\n",
      "NRMSModel(\n",
      "  (news_encoder): NewsEncoder(\n",
      "    (embedding): Embedding(250002, 768)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (multihead_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (attention): AttLayer2()\n",
      "  )\n",
      "  (candidate_encoder): NewsEncoder(\n",
      "    (embedding): Embedding(250002, 768)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (multihead_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (attention): AttLayer2()\n",
      "  )\n",
      "  (user_encoder): UserEncoder(\n",
      "    (news_encoder): NewsEncoder(\n",
      "      (embedding): Embedding(250002, 768)\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (multihead_attention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (attention): AttLayer2()\n",
      "    )\n",
      "    (multihead_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "    )\n",
      "    (additive_attention): AttLayer2()\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n",
      "Validation started ----\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 7.75 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 9.35 GiB is allocated by PyTorch, and 337.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     53\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnrms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhis_input_title\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_input_title\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[0;32m     57\u001b[0m val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\danie\\OneDrive - Danmarks Tekniske Universitet\\Autumn-2024\\pytorch-nrms\\NRMSModel.py:19\u001b[0m, in \u001b[0;36mNRMSModel.forward\u001b[1;34m(self, his_input_title, pred_input_title)\u001b[0m\n\u001b[0;32m     16\u001b[0m batch_size, npratio, title_size \u001b[38;5;241m=\u001b[39m pred_input_title\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Input size is (batch_size, history_size, title_size)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m user_present \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhis_input_title\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Output size is (batch_size, hidden_dim)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Reshape for titleencoder: treat each news title independently\u001b[39;00m\n\u001b[0;32m     23\u001b[0m user_present_unsqueezed \u001b[38;5;241m=\u001b[39m user_present\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\danie\\OneDrive - Danmarks Tekniske Universitet\\Autumn-2024\\pytorch-nrms\\user_encoder.py:41\u001b[0m, in \u001b[0;36mUserEncoder.forward\u001b[1;34m(self, his_input_title)\u001b[0m\n\u001b[0;32m     38\u001b[0m his_input_title_flat \u001b[38;5;241m=\u001b[39m his_input_title\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, title_size)  \u001b[38;5;66;03m# Shape: (batch_size * history_size, title_size)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Input size is (batch_size * history_size, title_size)\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m click_title_presents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnews_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhis_input_title_flat\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (batch_size * history_size, hidden_dim)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Output size is (batch_size * history_size, hidden_dim)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Reshape back to include history_size\u001b[39;00m\n\u001b[0;32m     46\u001b[0m click_title_presents \u001b[38;5;241m=\u001b[39m click_title_presents\u001b[38;5;241m.\u001b[39mview(batch_size, history_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch_size, history_size, hidden_dim)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\danie\\OneDrive - Danmarks Tekniske Universitet\\Autumn-2024\\pytorch-nrms\\news_encoder.py:42\u001b[0m, in \u001b[0;36mNewsEncoder.forward\u001b[1;34m(self, sequences_input_title)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m embedded_sequences\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Input size is (title_size, batch_size, embedded_dimension)\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Output size is (title_size, batch_size, embedded_dimension)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(y[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1368\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1343\u001b[0m         query,\n\u001b[0;32m   1344\u001b[0m         key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1368\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\functional.py:6242\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   6240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6241\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(q_scaled, k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m-> 6242\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   6244\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m dropout(attn_output_weights, p\u001b[38;5;241m=\u001b[39mdropout_p)\n",
      "File \u001b[1;32mc:\\Users\\danie\\anaconda3\\envs\\DeepLearningNew\\Lib\\site-packages\\torch\\nn\\functional.py:2140\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   2138\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   2139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2140\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2142\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.75 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 9.35 GiB is allocated by PyTorch, and 337.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "num_epochs = 100\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "\n",
    "word2vec_embedding = torch.tensor(word2vec_embedding, dtype=torch.float32).to(device)\n",
    "print(word2vec_embedding.shape)\n",
    "nrms = NRMSModel(hparams_nrms=hparams_nrms, word2vec_embedding=word2vec_embedding, seed=42).to(device) # Adding to device\n",
    "print(nrms)\n",
    "optimizer = torch.optim.Adam(nrms.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(\"./logs\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    nrms.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, ((his_input_title, pred_input_title), labels) in enumerate(train_dataloader):\n",
    "        his_input_title = his_input_title.to(device, dtype=torch.long)\n",
    "        pred_input_title = pred_input_title.to(device, dtype=torch.long)\n",
    "        labels = labels.to(device, dtype=torch.long).view(-1)\n",
    "        labels = labels.view(-1)\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = nrms(his_input_title, pred_input_title)  # Forward pass\n",
    "        loss = loss_fn(outputs.view(-1), labels.float())  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the parameters\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        # Detach tensors immediately after use to save memory\n",
    "        his_input_title = his_input_title.detach()\n",
    "        pred_input_title = pred_input_title.detach()\n",
    "        labels = labels.detach()\n",
    "        outputs = outputs.detach()\n",
    "        del his_input_title, pred_input_title, labels, outputs, loss\n",
    "        torch.cuda.empty_cache()  # Clear unused GPU memory\n",
    "        \n",
    "        \n",
    "    print(\"Validation started ----\")\n",
    "    # Validation\n",
    "    nrms.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (his_input_title, pred_input_title), labels in val_dataloader:\n",
    "            his_input_title = his_input_title.to(device, dtype=torch.long)\n",
    "            pred_input_title = pred_input_title.to(device, dtype=torch.long)\n",
    "            labels = labels.to(device, dtype=torch.long).view(-1)\n",
    "            labels = labels.view(-1)\n",
    "            \n",
    "            outputs = nrms(his_input_title, pred_input_title)\n",
    "            loss = loss_fn(outputs.view(-1), labels.float())\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            # Detach tensors immediately after use to save memory\n",
    "            del his_input_title, pred_input_title, labels, outputs, loss\n",
    "            torch.cuda.empty_cache()  # Clear unused GPU memory\n",
    "            \n",
    "    val_loss /= len(val_dataloader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {val_loss:.3f}, Accuracy: {accuracy:.2f}%\")\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 597s 8s/step - loss: 1.5952 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# MODEL_NAME = \"NRMS\"\n",
    "# LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "# MODEL_WEIGHTS = f\"downloads/data/state_dict/{MODEL_NAME}/weights\"\n",
    "\n",
    "# # CALLBACKS\n",
    "# # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "# # early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "# # modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "# #     filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    "# # )\n",
    "\n",
    "# hparams_nrms.history_size = HISTORY_SIZE\n",
    "\n",
    "\n",
    "# model = NRMSModel(\n",
    "#     hparams=hparams_nrms,\n",
    "#     word2vec_embedding=word2vec_embedding,\n",
    "#     seed=42,\n",
    "# )\n",
    "# hist = model.model.fit(\n",
    "#     train_dataloader,\n",
    "#     validation_data=val_dataloader,\n",
    "#     epochs=1,\n",
    "#     # callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    "# )\n",
    "# Uncomment the following line if you have pre-trained weights\n",
    "# _ = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/153 [==============================] - 383s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# pred_validation = model.scorer.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the predictions to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th><th>scores</th><th>is_known_user</th><th>ranked_scores</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>u32</td><td>list[i8]</td><td>list[f64]</td><td>bool</td><td>list[i64]</td></tr></thead><tbody><tr><td>386380</td><td>[9779867, 9779423, … 9779956]</td><td>[9787931, 9780460, … 9765777]</td><td>[9787465]</td><td>43657242</td><td>[0, 0, … 0]</td><td>[0.456477, 0.528305, … 0.508259]</td><td>true</td><td>[35, 13, … 23]</td></tr><tr><td>177925</td><td>[9777910, 9777769, … 9779511]</td><td>[8560195, 9486080, … 9790091]</td><td>[9789922]</td><td>110129832</td><td>[0, 0, … 0]</td><td>[0.520847, 0.433627, … 0.570924]</td><td>false</td><td>[3, 6, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ user_id ┆ article_id ┆ article_i ┆ article_i ┆ … ┆ labels    ┆ scores    ┆ is_known_ ┆ ranked_sc │\n",
       "│ ---     ┆ _fixed     ┆ ds_inview ┆ ds_clicke ┆   ┆ ---       ┆ ---       ┆ user      ┆ ores      │\n",
       "│ u32     ┆ ---        ┆ ---       ┆ d         ┆   ┆ list[i8]  ┆ list[f64] ┆ ---       ┆ ---       │\n",
       "│         ┆ list[i32]  ┆ list[i32] ┆ ---       ┆   ┆           ┆           ┆ bool      ┆ list[i64] │\n",
       "│         ┆            ┆           ┆ list[i32] ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 386380  ┆ [9779867,  ┆ [9787931, ┆ [9787465] ┆ … ┆ [0, 0, …  ┆ [0.456477 ┆ true      ┆ [35, 13,  │\n",
       "│         ┆ 9779423, … ┆ 9780460,  ┆           ┆   ┆ 0]        ┆ ,         ┆           ┆ … 23]     │\n",
       "│         ┆ 9779956]   ┆ …         ┆           ┆   ┆           ┆ 0.528305, ┆           ┆           │\n",
       "│         ┆            ┆ 9765777]  ┆           ┆   ┆           ┆ …         ┆           ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆ 0.508259] ┆           ┆           │\n",
       "│ 177925  ┆ [9777910,  ┆ [8560195, ┆ [9789922] ┆ … ┆ [0, 0, …  ┆ [0.520847 ┆ false     ┆ [3, 6, …  │\n",
       "│         ┆ 9777769, … ┆ 9486080,  ┆           ┆   ┆ 0]        ┆ ,         ┆           ┆ 1]        │\n",
       "│         ┆ 9779511]   ┆ …         ┆           ┆   ┆           ┆ 0.433627, ┆           ┆           │\n",
       "│         ┆            ┆ 9790091]  ┆           ┆   ┆           ┆ …         ┆           ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆ 0.570924] ┆           ┆           │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "#     add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    "# )\n",
    "# df_validation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MetricEvaluator class>: \n",
       " {\n",
       "    \"auc\": 0.523276170069743,\n",
       "    \"mrr\": 0.3271357380208631,\n",
       "    \"ndcg@5\": 0.368758819449155,\n",
       "    \"ndcg@10\": 0.44821698782392533\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics = MetricEvaluator(\n",
    "#     labels=df_validation[\"labels\"].to_list(),\n",
    "#     predictions=df_validation[\"scores\"].to_list(),\n",
    "#     metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    "# )\n",
    "# metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th><th>scores</th><th>is_known_user</th><th>ranked_scores</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>u32</td><td>list[i8]</td><td>list[f64]</td><td>bool</td><td>list[i64]</td></tr></thead><tbody><tr><td>386380</td><td>[9779867, 9779423, … 9779956]</td><td>[9787931, 9780460, … 9765777]</td><td>[9787465]</td><td>43657242</td><td>[0, 0, … 0]</td><td>[0.456477, 0.528305, … 0.508259]</td><td>true</td><td>[35, 13, … 23]</td></tr><tr><td>177925</td><td>[9777910, 9777769, … 9779511]</td><td>[8560195, 9486080, … 9790091]</td><td>[9789922]</td><td>110129832</td><td>[0, 0, … 0]</td><td>[0.520847, 0.433627, … 0.570924]</td><td>false</td><td>[3, 6, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 9)\n",
       "┌─────────┬────────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ user_id ┆ article_id ┆ article_i ┆ article_i ┆ … ┆ labels    ┆ scores    ┆ is_known_ ┆ ranked_sc │\n",
       "│ ---     ┆ _fixed     ┆ ds_inview ┆ ds_clicke ┆   ┆ ---       ┆ ---       ┆ user      ┆ ores      │\n",
       "│ u32     ┆ ---        ┆ ---       ┆ d         ┆   ┆ list[i8]  ┆ list[f64] ┆ ---       ┆ ---       │\n",
       "│         ┆ list[i32]  ┆ list[i32] ┆ ---       ┆   ┆           ┆           ┆ bool      ┆ list[i64] │\n",
       "│         ┆            ┆           ┆ list[i32] ┆   ┆           ┆           ┆           ┆           │\n",
       "╞═════════╪════════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 386380  ┆ [9779867,  ┆ [9787931, ┆ [9787465] ┆ … ┆ [0, 0, …  ┆ [0.456477 ┆ true      ┆ [35, 13,  │\n",
       "│         ┆ 9779423, … ┆ 9780460,  ┆           ┆   ┆ 0]        ┆ ,         ┆           ┆ … 23]     │\n",
       "│         ┆ 9779956]   ┆ …         ┆           ┆   ┆           ┆ 0.528305, ┆           ┆           │\n",
       "│         ┆            ┆ 9765777]  ┆           ┆   ┆           ┆ …         ┆           ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆ 0.508259] ┆           ┆           │\n",
       "│ 177925  ┆ [9777910,  ┆ [8560195, ┆ [9789922] ┆ … ┆ [0, 0, …  ┆ [0.520847 ┆ false     ┆ [3, 6, …  │\n",
       "│         ┆ 9777769, … ┆ 9486080,  ┆           ┆   ┆ 0]        ┆ ,         ┆           ┆ 1]        │\n",
       "│         ┆ 9779511]   ┆ …         ┆           ┆   ┆           ┆ 0.433627, ┆           ┆           │\n",
       "│         ┆            ┆ 9790091]  ┆           ┆   ┆           ┆ …         ┆           ┆           │\n",
       "│         ┆            ┆           ┆           ┆   ┆           ┆ 0.570924] ┆           ┆           │\n",
       "└─────────┴────────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_validation = df_validation.with_columns(\n",
    "#     pl.col(\"scores\")\n",
    "#     .map_elements(lambda x: list(rank_predictions_by_score(x)))\n",
    "#     .alias(\"ranked_scores\")\n",
    "# )\n",
    "# df_validation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using the validation, simply add the testset to your flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2446it [00:00, 23282.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping downloads\\predictions.txt to downloads\\predictions.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# write_submission_file(\n",
    "#     impression_ids=df_validation[DEFAULT_IMPRESSION_ID_COL],\n",
    "#     prediction_scores=df_validation[\"ranked_scores\"],\n",
    "#     path=\"downloads/predictions.txt\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearningNew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
